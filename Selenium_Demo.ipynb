{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17f76f9-688e-492e-8ec3-35d801ae4dad",
   "metadata": {},
   "source": [
    "# Scraping and Crawling Webpages using the Selenium Library\n",
    "\n",
    "Brad Marx\n",
    "\n",
    "\n",
    "- Introduction to Selenium\n",
    "- Web Scraping Considerations\n",
    "- Selenium Setup\n",
    "- Components of a Selenium Webscraper\n",
    "- Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9b0265-30d3-4cca-bbb5-62e6147170fb",
   "metadata": {},
   "source": [
    "## Introduction to Selenium\n",
    "\n",
    "###  What is Selenium?\n",
    "[Selenium](https://www.selenium.dev/) is a tool used to automate interactions with a web browser. \n",
    "\n",
    "While the library's initial purpose was to automate web application testing, the functionality it offers is comprehensive enough to find use in almost any web scraping/interaction use case.\n",
    "\n",
    "### How Does Selenium Work?\n",
    "\n",
    "Selenium simulates opening a web page in a web browser (like Chrome, Firefox, IE). A developer may then interact with the web page in the way it would be displayed to a user/customer/etc browsing the internet. \n",
    "\n",
    "Examples of interactions include (non-exhaustive):\n",
    "- Clicking on buttons\n",
    "- Executing JavaScript\n",
    "- Filling out embedded web forms\n",
    "- **Expanding drop-down menus**\n",
    "- **Scraping rendered HTML**\n",
    "- **Following hyperlinks to other pages**\n",
    "\n",
    "The focus of this demo will be on the last three general uses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f59e78-e208-46bc-9624-3c038e31e0e5",
   "metadata": {},
   "source": [
    "## Web Scraping Considerations\n",
    "\n",
    "### Ethical Considerations\n",
    "\n",
    "One should consider the effect of their web scraping use case on the websites to be scraped and the data to be collected: \n",
    "- Make sure the web scraper is not going to tax the server(s) of any target websites.\n",
    "    - Rapidly requesting resources (HTML, images, or other documents) from a site may strain the capabilities of their server and slow down (or even crash!) the website.\n",
    "    - This is more common for smaller sites with less resources available.\n",
    "- Only scrape data intended for the public. Try to avoid collecting personally identifiable information from sites unless given explicit permission for the use case.\n",
    "\n",
    "\n",
    "### Implementation Considerations\n",
    "\n",
    "The functionality and sohpistication of Selenium also makes it a very **heavy-weight** library for web scraping. Opening and simulating a browser incurs additional costs in time and resources that simpler web scraping implementations would avoid. \n",
    "\n",
    "If one only needs to retrieve data embedded in the HTML of *simple* web sites, they should see if the BeautifulSoup and URLLib/requests libraries alone would work for their use case. \n",
    "- This approach would simply retrieve the main DOM ([Document Object Model](https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model), basically the HTML and JavaScript) directly from a web server as a string for parsing in BeautifulSoup.\n",
    "- Skipping the overhead of first rendering a web page in a browser makes web scraping MUCH FASTER!\n",
    "\n",
    "#### So, why even bother with Selenium for web scraping? \n",
    "\n",
    "Many modern websites have more sophisticated HTML/CSS/JavaScript that may render information in ways that cannot be accessed directly from the main DOM. For example: \n",
    "- Links from dropdown menus (or any HTML tag set to `[aria-expanded='false']`)\n",
    "- Data in [Iframes](https://www.w3schools.com/html/html_iframe.asp) (embedded web pages in another web page)\n",
    "- Dynamic text, or data that depends on the browser window size to appear\n",
    "\n",
    "Any interaction with elements on a web page will also require Selenium.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c0d77d-f25a-467d-b5a9-183a2d0cea2e",
   "metadata": {},
   "source": [
    "## Selenium Setup\n",
    "\n",
    "1. Install the Selenium library into your environment. Run `conda env create -f selenium.yml` in the root of this repository to create such an environment.\n",
    "     \n",
    "\n",
    "2. Install browser of choice. I am using Chrome.\n",
    "\n",
    "3. Install required web driver\n",
    "   - Selenium requires a web driver executable to use in simulating a browser.\n",
    "   - Managing the proper browser and webdriver versions is a pain! We can use webdriver_manager to install and use the correct driver for our browser version.\n",
    "   - *Note*: More recent versions of Selenium have a built-in 'selenium manager' that managese the driver for you behind the scenes. However, the functionality is a little finicky, so I am opting to use the webdriver_manager object in the demo to be more explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ef6f16-8207-4b14-b877-57d4ac53fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup, NavigableString, CData, Tag\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f41cb845-a54d-435d-b858-589779986940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define service object that contains info on web driver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "# Define options object that contains metadata on the browser. This can be customized in a number of ways (more on that later) \n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "# Create the driver. This is the 'browser simulation' object! If this cell runs correctly, you should see a new empty window appear using your browser of choice.\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae24006-9950-421a-b3f1-01d5074666a1",
   "metadata": {},
   "source": [
    "## Components of a Selenium Web Scraper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44acae-2060-46e8-84a7-89aaccb7f8c7",
   "metadata": {},
   "source": [
    "## Selenium Demo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b50f6b-d7c6-48bf-a236-773e591f154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
